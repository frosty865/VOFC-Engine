// Storage bucket diagnostic script
// Run this to check if storage buckets are properly configured

import { createClient } from '@supabase/supabase-js';

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
);

async function diagnoseStorageBuckets() {
  console.log('ğŸ” Diagnosing Supabase Storage Buckets...\n');

  try {
    // Check if buckets exist
    const { data: buckets, error: bucketsError } = await supabase.storage.listBuckets();
    
    if (bucketsError) {
      console.error('âŒ Error listing buckets:', bucketsError);
      return;
    }

    console.log('ğŸ“¦ Available buckets:');
    buckets.forEach(bucket => {
      console.log(`  - ${bucket.name} (${bucket.public ? 'public' : 'private'})`);
    });

    // Check required buckets
    const requiredBuckets = ['documents', 'Parsed', 'processed-documents'];
    const existingBuckets = buckets.map(b => b.name);
    
    console.log('\nğŸ” Checking required buckets:');
    requiredBuckets.forEach(bucketName => {
      if (existingBuckets.includes(bucketName)) {
        console.log(`  âœ… ${bucketName} - exists`);
      } else {
        console.log(`  âŒ ${bucketName} - missing`);
      }
    });

    // Test file upload to documents bucket
    console.log('\nğŸ§ª Testing file upload to documents bucket...');
    const testFileName = `test-${Date.now()}.pdf`;
    const testContent = Buffer.from('Test PDF content');
    
    const { data: uploadData, error: uploadError } = await supabase.storage
      .from('documents')
      .upload(testFileName, testContent, {
        contentType: 'application/pdf',
        cacheControl: '3600'
      });

    if (uploadError) {
      console.error('âŒ Upload test failed:', uploadError);
    } else {
      console.log('âœ… Upload test successful:', uploadData.path);
      
      // Clean up test file
      await supabase.storage.from('documents').remove([testFileName]);
      console.log('ğŸ§¹ Test file cleaned up');
    }

    // Test JSON upload to Parsed bucket
    console.log('\nğŸ§ª Testing JSON upload to Parsed bucket...');
    const testJsonFileName = `test-${Date.now()}.json`;
    const testJsonContent = JSON.stringify({ test: 'data' });
    
    const { data: jsonUploadData, error: jsonUploadError } = await supabase.storage
      .from('Parsed')
      .upload(testJsonFileName, Buffer.from(testJsonContent, 'utf8'), {
        contentType: 'application/json',
        cacheControl: '3600'
      });

    if (jsonUploadError) {
      console.error('âŒ JSON upload test failed:', jsonUploadError);
    } else {
      console.log('âœ… JSON upload test successful:', jsonUploadData.path);
      
      // Clean up test file
      await supabase.storage.from('Parsed').remove([testJsonFileName]);
      console.log('ğŸ§¹ Test JSON file cleaned up');
    }

    // Check bucket policies
    console.log('\nğŸ”’ Checking bucket policies...');
    const { data: policies, error: policiesError } = await supabase.rpc('get_storage_policies');
    
    if (policiesError) {
      console.log('âš ï¸ Could not retrieve policies (this is normal if RLS is not enabled)');
    } else {
      console.log('ğŸ“‹ Storage policies:', policies);
    }

  } catch (error) {
    console.error('âŒ Diagnostic error:', error);
  }
}

// Run diagnostics
diagnoseStorageBuckets();
